# ğŸ–¥ï¸ Estimador de Memoria GPU para IA

Este script permite estimar el consumo de memoria GPU necesario para cargar un modelo de inteligencia artificial desde Hugging Face, considerando distintos formatos de datos.

## ğŸš€ CaracterÃ­sticas
âœ… Calcula la memoria necesaria en GB segÃºn el nÃºmero de parÃ¡metros del modelo.  
âœ… Compatible con distintos formatos de precisiÃ³n: `int4`, `int8`, `float8`, `float16`, `float32`.  
âœ… Usa metadatos de Hugging Face para obtener informaciÃ³n del modelo.  
âœ… FÃ¡cil de usar desde la lÃ­nea de comandos.  

## ğŸ“¥ InstalaciÃ³n
Para utilizar este estimador, instala las dependencias necesarias:
```bash
pip install huggingface_hub
```

## âš™ï¸ Uso
Ejecuta el script con el ID del modelo en Hugging Face:
```bash
python estimador_gpu.py <model_id>
```
Por ejemplo:
```bash
python estimador_gpu.py meta-llama/Llama-2-7b
```
Opcionalmente, puedes especificar el tipo de dato:
```bash
python estimador_gpu.py meta-llama/Llama-2-7b --dtype float16
```

## ğŸ“Œ Notas
- El cÃ¡lculo de memoria se basa en una estimaciÃ³n y puede variar segÃºn la implementaciÃ³n del modelo y optimizaciones especÃ­ficas.
- Si el modelo no tiene metadatos disponibles en Hugging Face, el script mostrarÃ¡ un error.

## â­ Â¡Apoya el proyecto!
Si este proyecto te resulta Ãºtil, **dale una estrella â­ en GitHub!**  
ğŸ”— [GitHub Repo](https://github.com/marcmayol/Arsenal-IA)
